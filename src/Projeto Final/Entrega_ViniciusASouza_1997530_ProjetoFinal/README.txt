Execução do trabalho:

1- Iniciar o notebook 'Split/split.ipynb' e rodar todo o algoritmo
2 - Exportar a pasta gerada pelo algoritmo (data_tt_g) para o diretório de testes (../Testes)
3 - Iniciar os testes rodando os notebooks com os nomes:
    100epochs_32batch_0.2dropout_0.001learningrate_128x128.ipynb
    100epochs_32batch_0.2dropout_0.0001learningrate_128x128.ipynb
    100epochs_16batch_0.2dropout_0.001learningrate_128x128.ipynb
    100epochs_16batch_0.2dropout_0.0001learningrate_128x128.ipynb
    100epochs_32batch_0.1dropout_0.001learningrate_128x128.ipynb
    100epochs_32batch_0.1dropout_0.0001learningrate_128x128.ipynb
    100epochs_16batch_0.1dropout_0.001learningrate_128x128.ipynb
    100epochs_16batch_0.1dropout_0.0001learningrate_128x128.ipynb

**Todas as bibliotecas utilizadas estão importadas devidamente em seus respectivos arquivos**

Bibliotecas Utilizadas:
-random
- tqdm
- shutil
- pathlib
- tensorflow
- numpy
- pandas
- sklearn
- matplotlib
- seaborn
- os